[{"content":"什么是数值字面量 数值字面量（Numeric Literals）在编程中是表示特定数值的一个符号或一组符号。这些字面量用于直接在源代码中表示一个数值，无需进行任何计算。例如 123、3.14、0xFF、1.23e-4 都可以被视为数值字面量。\n字面量的类型通常根据其格式和位置决定。例如在大多数编程语言[1][2][3]中，带有小数点的数字将被视为浮点数（如 3.14 ），而没有小数点的数字将被视为整数（如 123 ）。\n更复杂的编程语言可能支持其他类型的数值字面量，例如复数、大整数、无穷大、NaN（不是一个数字）等。\n本章将从数值字面量的解析入手，开始进入编译器构造的世界。\nCarbon数值类型介绍 Carbon中数值类型[4][5]有如下几种：\n整数类型\n整数根据进制分为如下类型：十进制（例如 12345 ）、十六进制（例如 0x1FE ）、二进制（例如 0b1010 ）等\n实数类型\n实数类型总是包含 . 符号，实数类型例如基础类型 123.456 以及科学技术法表示 123.456e789、0x1.2p123 等，其中科学技术法表示中的字符 e 及 p 在Carbon中称为指数（对应代码中exponent 字符，实际在幂运算中应为底数），对于一个十进制值 N 来说，e 相当于10±N，而 p 相当于2±N。\n且实数类型字面量 exponent 字符后可跟随 + 或 - 字符，例如 12.34e+56 或 56.34e-12。\n数字分隔符[6]\n数字分隔符由下划线 _ 表示，例如十进制数: 1_23_456_7890、十六进制数: 0x7_F_FF_FFFF、实数: 2_147.48_3648e12_345 或 0x1_00CA.FE_F00Dp+2_4、二进制数: 0b1_000_101_11 等。\n数值字面量词法解析： 首先需要在字符串层面对数值字面量进行字符串切分，由于字符中数字分隔符即 _ 下划线只用于提升长数值的阅读性，对其不做处理，而其他字符如小数点及 exponent 字符需要获取其在字符串中所在位置，便于下一步的处理。于是在词法层面提供NumericLiteralToken类的抽象，需要存储的数据有：字符数据（text）、小数点字符位置（radix_point）、指数幂字符位置（exponent）。\n以下代码参考numeric_literal section1\nclass NumericLiteralToken { public: auto Text() const -\u0026gt; llvm::StringRef { return text; } static auto Lex(llvm::StringRef source_text) -\u0026gt; llvm::Optional\u0026lt;NumericLiteralToken\u0026gt;; auto GetRadixPoint() -\u0026gt; int { return radix_point; } auto GetExponent() -\u0026gt; int { return exponent; } private: NumericLiteralToken() {} llvm::StringRef text; // \u0026#39;.\u0026#39;字符的偏移量 int radix_point; // \u0026#39;e\u0026#39;或\u0026#39;p\u0026#39;字符的偏移量 int exponent; }; 其中我们重点关注Lex接口的实现：\nauto NumericLiteralToken::Lex(llvm::StringRef source_text) -\u0026gt; llvm::Optional\u0026lt;NumericLiteralToken\u0026gt; { NumericLiteralToken result; // 判断source_text是否为空以及第一个字符是否为数字 if (source_text.empty() || !IsDecimalDigit(source_text.front())) { return llvm::None; } bool seen_plus_minus = false; bool seen_radix_point = false; bool seen_potential_exponent = false; // 由于之前已经确认过首字符，这里索引从1开始 int i = 1; for (int n = source_text.size(); i != n; ++i) { char c = source_text[i]; if (IsAlnum(c) || c == \u0026#39;_\u0026#39;) { // 只支持小写的 \u0026#39;e\u0026#39;，如果存在该字符且发现点号以及未探索 // 到加减号则记录exponent索引位置，否则继续下一轮循环 if (IsLower(c) \u0026amp;\u0026amp; seen_radix_point \u0026amp;\u0026amp; !seen_plus_minus) { result.exponent = i; seen_potential_exponent = true; } continue; } // 当前字符为 \u0026#39;.\u0026#39; 时，记录radix_point if (c == \u0026#39;.\u0026#39; \u0026amp;\u0026amp; i + 1 != n \u0026amp;\u0026amp; IsAlnum(source_text[i + 1]) \u0026amp;\u0026amp; !seen_radix_point) { result.radix_point = i; seen_radix_point = true; continue; } // 当前字符为 \u0026#39;+\u0026#39; 或 \u0026#39;-\u0026#39; 时，记录seen_plus_minus if ((c == \u0026#39;+\u0026#39; || c == \u0026#39;-\u0026#39;) \u0026amp;\u0026amp; seen_potential_exponent \u0026amp;\u0026amp; result.exponent == i - 1 \u0026amp;\u0026amp; i + 1 != n \u0026amp;\u0026amp; IsAlnum(source_text[i + 1])) { assert(!seen_plus_minus \u0026amp;\u0026amp; \u0026#34;should only consume one + or -\u0026#34;); seen_plus_minus = true; continue; } break; } // 返回探索到的字符串，以当前i的值为索引切分子串 result.text = source_text.substr(0, i); // 记录 \u0026#39;.\u0026#39; 偏移 if (!seen_radix_point) { result.radix_point = i; } // 记录 \u0026#39;e\u0026#39; 或 \u0026#39;p\u0026#39; 偏移 if (!seen_potential_exponent) { result.exponent = i; } return result; } 以上代码中，source_text用于接受外部传入的数值字符串，该类型为llvm::StringRef类型（StringRef类型分析可参考chapter12_s1.2: LLVM ADT StringRef介绍及使用），首先判断source_text是否为空以及第一个字符是否为数字，如果不满足条件则返回llvm::None，llvm::None实际为一个枚举数值类型，返回值为llvm::Optional（Optional类型分析可参考chapter12_s1.3: LLVM ADT Optional介绍及使用）。\n接下来使用三个变量seen_plus_minus（是否探索到 + 或 - ）、seen_radix_point（是否探索到 . ）、seen_potential_exponent（是否探索到 e 或者 p ）用于后续词法解析的条件判断。\n在下一步字符串循环中，不断去除当前字符并做判断，直到不满足所以条件判断要求跳出循环。\n跳出循环后记录对应数据存入返回值NumericLiteralToken对象的变量中。\n数值字面量语法解析 在词法层面我们切分并完成了NumericLiteralToken对象的解析，接下来需要实现数值字面量的解析，实现这一步的目标是在语义上能对不同数值字面量提取更多的信息，其中包括数值字面量的合规性检查、提取数据等，将数值字面量解析拆分为了Tokenizer和Parser两部分，使得每部分过程更为明确和便于后期扩展。\n我们关注numeric_literal代码section2中的友元类Parser实现，将section1中NumericLiteralToken里两个函数GetRadixPoint和GetExponent的能力删除，将提取对应数据的能力移交至Parser，函数返回值改为llvm::APInt（参考阅读什么是APInt链接）。\n以下代码参考numeric_literal section2\nclass NumericLiteralToken::Parser { public: Parser(NumericLiteralToken literal); auto IsInteger() -\u0026gt; bool { return literal.radix_point == static_cast\u0026lt;int\u0026gt;(literal.Text().size()); } auto GetRadix() const -\u0026gt; int { return radix; } auto GetMantissa() -\u0026gt; llvm::APInt; auto GetExponent() -\u0026gt; llvm::APInt; private: NumericLiteralToken literal; // 存储对应字面量 // 基数默认为10，可以为 2 或 10 或 16 int radix = 10; // 词法结构：[radix] int_part [. fract_part [[ep] [+-] exponent_part]] llvm::StringRef int_part; // 整数部分 llvm::StringRef fract_part; // 小数部分 llvm::StringRef exponent_part; // 指数部分 // 对应数据是否需要清除`_`或`.`符号，默认为false bool mantissa_needs_cleaning = false; bool exponent_needs_cleaning = false; // 在`exponent`部分后面发现了`-`符号 bool exponent_is_negative = false; }; 具体看一下Parser的构造函数，构造时传入NumericLiteralToken对象，根据该对象里的radix_point数据进行int_part数据的切分，并对切分结果前两个字符做检查，根据0x或0b首字符判断进制，随即切分fract_part数据以及exponent_part数据，并判断是否在exponent部分后面发现了-符号。\nNumericLiteralToken::Parser::Parser(NumericLiteralToken literal) : literal(literal) { int_part = literal.text.substr(0, literal.radix_point); if (int_part.consume_front(\u0026#34;0x\u0026#34;)) { radix = 16; } else if (int_part.consume_front(\u0026#34;0b\u0026#34;)) { radix = 2; } fract_part = literal.text.substr(literal.radix_point + 1, literal.exponent - literal.radix_point - 1); exponent_part = literal.text.substr(literal.exponent + 1); if (!exponent_part.consume_front(\u0026#34;+\u0026#34;)) { exponent_is_negative = exponent_part.consume_front(\u0026#34;-\u0026#34;); } } Parser构造函数中构建好数据后，需要提供接口获取对应数据。\n其中包括四个函数接口：\nauto IsInteger() -\u0026gt; bool; auto GetRadix() const -\u0026gt; int; auto GetMantissa() -\u0026gt; llvm::APInt; auto GetExponent() -\u0026gt; llvm::APInt; IsInteger()用于判断是否为一个整数，判断方式为小数点位置是否在字符串末尾，字符串显示不存在小数点时，小数点默认在末尾。 GetRadix()用于获取进制。 GetMantissa()用于获取小数部分。 GetExponent()用于获取指数部分。 其中GetMantissa()和GetExponent()都调用了ParseInteger接口，ParseInteger完成获取具体数值的功能，以下为ParseInteger接口代码分析：\nstatic auto ParseInteger(llvm::StringRef digits, int radix, bool needs_cleaning) -\u0026gt; llvm::APInt { llvm::SmallString\u0026lt;32\u0026gt; cleaned; // 预分配32个字节的字符串 if (needs_cleaning) { cleaned.reserve(digits.size()); // 根据目标大小重建长度 std::remove_copy_if(digits.begin(), digits.end(), std::back_inserter(cleaned), [](char c) { return c == \u0026#39;_\u0026#39; || c == \u0026#39;.\u0026#39;; }); digits = cleaned; } llvm::APInt value; if (digits.getAsInteger(radix, value)) { llvm_unreachable(\u0026#34;should never fail\u0026#34;); } return value; } 当解析包含小数点和下划线的字面量时，将忽视这两种字符，例如在解析 123.456e7 字面量时，我们期望获取到小数部分mantissa即(123456)和指数部分exponent(7-3=4)，根据这两个数我们能计算出真实的数据为：1234560000，其中GetMantissa函数如下：\nauto NumericLiteralToken::Parser::GetMantissa() -\u0026gt; llvm::APInt { // 如果为整数从int_part为结尾，否则以fract_part为结尾 const char* end = IsInteger() ? int_part.end() : fract_part.end(); llvm::StringRef digits(int_part.begin(), end - int_part.begin()); return ParseInteger(digits, radix, mantissa_needs_cleaning); } 获取exponent的函数GetExponent如下：\nauto NumericLiteralToken::Parser::GetExponent() -\u0026gt; llvm::APInt { llvm::APInt exponent(64, 0); // 创建64位值为0的exponent对象。 // 如果存在指数部分，就进入这个分支。 if (!exponent_part.empty()) { // 解析指数部分。这个函数会将字符串形式的指数转换为整数。其中， // 第一个参数是指数部分，第二个参数10是代表十进制，第三个参数 // 表示解析过程中是否需要进行清理。 exponent = ParseInteger(exponent_part, 10, exponent_needs_cleaning); // 检查指数的符号位是否被设置，或者指数的位宽是否小于64。 // 如果满足这些条件之一，就需要扩展指数的位宽。 if (exponent.isSignBitSet() || exponent.getBitWidth() \u0026lt; 64) { // 扩展指数的位宽。新的位宽至少为64，如果原来的位宽+1大于64， // 那么就使用原来的位宽+1。扩展后，新增的位都被设置为0。 exponent = exponent.zext(std::max(64U, exponent.getBitWidth() + 1)); } // 如果指数是负数，就需要取反。 if (exponent_is_negative) { exponent.negate(); // 取反操作。 } } // 计算小数部分的字符数量，这个数量会影响实际的指数大小。 int excess_exponent = fract_part.size(); // 如果基数是16，即如果是十六进制的数，那么每一个小数部 // 分的字符都会减少4个指数（因为一个十六进制的字符等于4个二进制位）。 if (radix == 16) { excess_exponent *= 4; // 将小数部分的字符数量乘以4。 } exponent -= excess_exponent; // 从指数中减去小数部分的字符数量。 // 如果原来的指数是负数，但是计算后的指数变为非负，那么就进入这个分支。 if (exponent_is_negative \u0026amp;\u0026amp; !exponent.isNegative()) { // 扩展指数的位宽，新增的位被设置为0。 exponent = exponent.zext(exponent.getBitWidth() + 1); // 设置指数的符号位，使得指数变为负数。 exponent.setSignBit(); } return exponent; } 从上面我们可以看到mantissa_needs_cleaning和exponent_needs_cleaning永远为false，原因是因为这两个标志位需要在获取数据之前对字面量做检查后进行设置，对传入不满足要求的字面量做预处理检查后才允许提取。\n关于字面量检查部分在下一章Chapter2: 诊断信息中进行说明与分析。\n引用 [1] : Floating-point numeric types - C# reference | Microsoft Learn [2] : numeric_literals | MDN Web [3] : json-tutorial | miloyip [4] : numeric_literals | Carbon [5] : proposals 0143 | Carbon [6] : proposals 1983 | Carbon ","permalink":"https://canftin.github.io/posts/tech/%E4%BB%8E%E9%9B%B6%E6%9E%84%E9%80%A0%E7%8E%B0%E4%BB%A3%E8%AF%AD%E8%A8%80%E7%BC%96%E8%AF%91%E5%99%A81-%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/","summary":"什么是数值字面量 数值字面量（Numeric Literals）在编程中是表示特定数值的一个符号或一组符号。这些字面量用于直接在源代码中表示一个","title":"从零构造现代语言编译器(1): 词法分析"},{"content":"carbon-lang介绍 Carbon作为一个实验性的通用编程语言，旨在成为“C++的后继语言”[1]，目前仍在Google的项目孵化期中，预计2-3年内结束实验[2]。\nCarbon官方项目选择Bazel构建工具，一方面是因为Google内部工具链的高可用性，相比于Go语言早期构建方式，作为同样出自Google之手的Carbon语言，避免手搓Makefile的繁琐，选用更加现代的工具链作为构建工具，另一方面也由于Google在LLVM之上的积累和贡献[3]，LLVM目前仓库中Bazel构建方式由Google团队完成及合并（不过经过测试发现，存在年久失修的问题[4]）。\n本项目介绍及依赖安装 本项目基于Carbon，为深入剖析现代编译器前端实现以及LLVM工具链上层使用，一步一步实现名为Cocktail（鸡尾酒）的语言，代码协议遵从官方仓库Lisence[5]，项目按照LLVM仓库主流构建方式和代码结构组织，使用CMake、Google test、Google mock等工具完成。\n本项目在Ubuntu 22.04系统环境下测试完成，其他环境暂未测试，需要安装的依赖环境参考如下命令：\nsudo apt-get install cmake g++ clang bison flex libgtest-dev libgmock-dev make valgrind libbenchmark-dev llvm-15-dev CMake项目结构 首先从0到1构建CMake项目结构，参照clang的项目结构，project_structure代码如下：\n. ├── CMakeLists.txt ├── include │ └── Cocktail │ └── Lexer │ └── Basic.h ├── lib │ └── Lexer │ └── Basic.cc └── unittests ├── CMakeLists.txt └── Lexer ├── Basic.t.cc └── CMakeLists.txt 其中include作为Cocktail的头文件目录，lib作为Cocktail的库文件目录，其中C++文件一律以.cc作为后缀，unittests作为Cocktail单元测试文件目录，并且其中单元测试一律以.t.cc作为后缀，单元测试依赖头文件以.t.h为后缀。\n可在该目录下执行如下命令完成构建（make），或自行选用Ninja build：\n\u0026gt; mkdir build \u0026gt; cd build \u0026gt; cmake .. \u0026gt; make -j$(nproc) \u0026gt; ctest -j$(nproc) cmake构建结果如下：\n-- The C compiler identification is GNU 11.3.0 -- The CXX compiler identification is GNU 11.3.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /usr/bin/cc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- Project: \u0026#39;cocktail\u0026#39; -- Performing Test HAVE_FFI_CALL -- Performing Test HAVE_FFI_CALL - Success -- Found FFI: /usr/lib/x86_64-linux-gnu/libffi.so -- Performing Test Terminfo_LINKABLE -- Performing Test Terminfo_LINKABLE - Success -- Found Terminfo: /usr/lib/x86_64-linux-gnu/libtinfo.so -- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \u0026#34;1.2.11\u0026#34;) -- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version \u0026#34;2.9.13\u0026#34;) -- Looking for pthread.h -- Looking for pthread.h - found -- Performing Test CMAKE_HAVE_LIBC_PTHREAD -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success -- Found Threads: TRUE -- unittest files found: Basic.t.cc -- Configuring done -- Generating done -- Build files have been written to: /carbon-blog/code/project_structure/build make构建结果如下：\n[ 25%] Building CXX object CMakeFiles/cocktail.dir/lib/Lexer/Basic.cc.o [ 50%] Linking CXX static library libcocktail.a [ 50%] Built target cocktail [ 75%] Building CXX object unittests/Lexer/CMakeFiles/Basic.t.dir/Basic.t.cc.o [100%] Linking CXX executable Basic.t [100%] Built target Basic.t ctest构建结果如下：\nTest project /carbon-blog/code/project_structure/build Start 1: Basic.t 1/2 Test #1: Basic.t .......................... Passed 0.01 sec Start 2: Basic.t-memory-check 2/2 Test #2: Basic.t-memory-check ............. Passed 0.97 sec 100% tests passed, 0 tests failed out of 2 Total Test time (real) = 0.98 sec 介绍CMake构建文件 在主目录下CMakeList.txt文件中可以看到这条add_compile_options(-fno-rtti)编译选项，这里表明禁用C++的RTTI特性，由于LLVM实现了自己的一套RTTI机制，此处加入该选项禁用。\nset(LLVM_DIR /usr/lib/llvm-15/lib/cmake/llvm)设置LLVM路径，由于上述使用apt包管理安装llvm-15-dev，LLVM默认CMake路径为/usr/lib/llvm-15/lib/cmake/llvm。\n同时需要加入如下条件使得项目完成LLVM的引入：\nfind_package(LLVM REQUIRED CONFIG) include_directories(${LLVM_INCLUDE_DIRS}) add_definitions(${LLVM_DEFINITIONS}) 关于内存泄漏检查，使用valgrind工具，将其加入ctest中，对编译出的二进制目标进行测试：\nfind_program(CMAKE_MEMORYCHECK_COMMAND valgrind) set(memcheck_command ${CMAKE_MEMORYCHECK_COMMAND} ${CMAKE_MEMORYCHECK_COMMAND_OPTIONS} --error-exitcode=1 --leak-check=full) add_test(${FILE_NAME}-memory-check ${memcheck_command} ./${FILE_NAME}) clang-format使用 clang-format作为LLVM官方提供的自动格式化工具，能够格式化排版C++代码，统一代码样式，本仓库代码一律使用官方.clang-format[6]配置。\nclang-tidy使用 clang-tidy作为C++的静态检查工具，因为它基于AST，比基于正则表达式的静态检查工具更为精准。本仓库代码一律使用官方.clang-tidy[7]配置。\n项目调试的前置知识 由于本项目基于LLVM，需要用到诸如StringRef、SmallVector等LLVM基础工具，在使用lldb vscode前端调试时存在难以打印的问题，这里需要引入LLVM官方仓库中lldbDataFormatters插件[8]，得以直观显示LLVM数据结构。\n引用 [1] : “C++的后继语言”\n[2] : 实验\n[3] : 贡献\n[4] : 年久失修的问题\n[5] : 官方仓库Lisence\n[6] : .clang-format\n[7] : .clang-tidy\n[8] : lldbDataFormatters插件\n","permalink":"https://canftin.github.io/posts/tech/%E4%BB%8E%E9%9B%B6%E6%9E%84%E9%80%A0%E7%8E%B0%E4%BB%A3%E8%AF%AD%E8%A8%80%E7%BC%96%E8%AF%91%E5%99%A80-%E5%BC%80%E5%A7%8B/","summary":"carbon-lang介绍 Carbon作为一个实验性的通用编程语言，旨在成为“C++的后继语言”[1]，目前仍在Google的项目孵化期中，","title":"从零构造现代语言编译器(0): 开始"},{"content":"这个博客从16年开始就在尝试用各种前端构建，期间也经历了WordPress、hexo等工具的使用，一直没有产出多少实质性的文章，虽然 这么多年我个人陆陆续续整理了一些资料和笔记，但只适合我自己查找回顾，导致思维脉络过于零散，不够系统。 我现在的工作专注于编译器开发，目前工作三年，前两年一直在做一些后端业务型的服务或工具的开发，近一年主要集中在底层语言编译器 以及ai编译器开发部分。重启这个博客，一方面想让自己开始保持一定的知识整理习惯，增强语言输出能力，另一方面也是总结归纳底层 系统知识。最近的一个愿景就是先成体系地输出关于现代语言编译器的构造系列文章，尝试去从源码分析的角度完整剖析语言编译器的构成， 希望从这里开始重新投入。\n","permalink":"https://canftin.github.io/posts/tech/%E5%8D%9A%E5%AE%A2%E7%9A%84%E9%87%8D%E5%90%AF/","summary":"这个博客从16年开始就在尝试用各种前端构建，期间也经历了WordPress、hexo等工具的使用，一直没有产出多少实质性的文章，虽然 这么多年","title":"博客的重启"},{"content":"我是矩木，目前专注于编译器开发，我的GitHub。\n","permalink":"https://canftin.github.io/about/","summary":"我是矩木，目前专注于编译器开发，我的GitHub。","title":"关于我"}]